{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c34e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94de7c0f",
   "metadata": {},
   "source": [
    "## Loading Environment File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ed3d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for dev.env at: C:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.env\n",
      "Loaded environment variables from dev.env\n",
      "GOOGLE_API_KEY loaded: True\n",
      "OPENROUTER_API_KEY loaded: True\n"
     ]
    }
   ],
   "source": [
    "secret_path = Path(\"../.env\")\n",
    "print(\"Looking for dev.env at:\", secret_path.resolve())\n",
    "if secret_path.exists():\n",
    "    load_dotenv(secret_path)\n",
    "    print(\"Loaded environment variables from dev.env\")\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found in environment variables or dev.env file.\")\n",
    "print(\"GOOGLE_API_KEY loaded:\", bool(GOOGLE_API_KEY))\n",
    "\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if not OPENROUTER_API_KEY:\n",
    "    raise ValueError(\"OPENROUTER_API_KEY not found in environment variables or dev.env file.\")\n",
    "print(\"OPENROUTER_API_KEY loaded:\", bool(OPENROUTER_API_KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac637f7",
   "metadata": {},
   "source": [
    "## Setup: Imports, Retry Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b1045e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "from google.genai import types\n",
    "from google.adk.apps.app import App, EventsCompactionConfig\n",
    "from google.adk.sessions import DatabaseSessionService\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "\n",
    "print(\"✅ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade5c5f6",
   "metadata": {},
   "source": [
    "Add the project root to sys.path to easily import our classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc10e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Ensure the project root (the parent of the \"src\" directory) is on sys.path\n",
    "# so that \"import src.model\" finds the src package under the project root.\n",
    "project_root = Path.cwd().parent\n",
    "src_dir = project_root / \"src\"\n",
    "\n",
    "project_root_path = str(project_root.resolve())\n",
    "if project_root_path not in sys.path:\n",
    "    sys.path.insert(0, project_root_path)\n",
    "\n",
    "from src.model import Intensity, SentimentOutput\n",
    "from src.model.rag_output import RagOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ed73b",
   "metadata": {},
   "source": [
    "Create a general retry policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbbf828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88d2e69",
   "metadata": {},
   "source": [
    "## Agents Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d391f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAG created.\n"
     ]
    }
   ],
   "source": [
    "# RAG system\n",
    "rag_agent = Agent(\n",
    "    name=\"RAG_Vaccine_Informer\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\", \n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"XXX\"\"\",\n",
    "    tools=[],\n",
    "    output_key=\"rag_output\",  # The result of this agent will be stored in the session state with this key.\n",
    "    output_schema=RagOutput,  # Define the expected output schema\n",
    ")\n",
    "\n",
    "print(\"✅ RAG created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0edc4298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ sentiment_agent created.\n"
     ]
    }
   ],
   "source": [
    "# Health Researcher: Focuses on medical breakthroughs.\n",
    "sentiment_agent = Agent(\n",
    "    name=\"sentiment_analysis\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"XXX\"\"\",\n",
    "    tools=[],\n",
    "    output_key=\"sentiment_output\",  # The result will be stored with this key.\n",
    "    output_schema=SentimentOutput,  # Define the expected output schema.\n",
    ")\n",
    "\n",
    "print(\"✅ sentiment_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd8937c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ aggregator_agent created.\n"
     ]
    }
   ],
   "source": [
    "# The AggregatorAgent runs *after* the parallel step to synthesize the results.\n",
    "aggregator_agent = Agent(\n",
    "    name=\"AggregatorAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n",
    "    instruction=\"\"\"Combine these findings into a single executive summary:\n",
    "\n",
    "    **RAG output:**\n",
    "    {rag_output}\n",
    "    \n",
    "    **User sentiment analysis:**\n",
    "    {sentiment_output}\n",
    "\"\"\",\n",
    "    output_key=\"final_output\",  # This will be the final output of the entire system.\n",
    ")\n",
    "\n",
    "print(\"✅ aggregator_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f939f143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parallel and Sequential Agents created.\n"
     ]
    }
   ],
   "source": [
    "# The ParallelAgent runs all its sub-agents simultaneously.\n",
    "parallel_rag_sentiment_agent = ParallelAgent(\n",
    "    name=\"ParallelRAGAndSentimentTeam\",\n",
    "    sub_agents=[sentiment_agent, rag_agent],\n",
    ")\n",
    "\n",
    "# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"ResearchSystem\",\n",
    "    sub_agents=[parallel_rag_sentiment_agent, aggregator_agent],\n",
    ")\n",
    "\n",
    "print(\"✅ Parallel and Sequential Agents created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea05b4",
   "metadata": {},
   "source": [
    "## Engine Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7429f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"VaxTalkAssistant\"\n",
    "SQL_ASYNC_DRIVER = \"aiosqlite\"\n",
    "DB_URL = f\"sqlite+{SQL_ASYNC_DRIVER}:///vaxtalk_sessions.db\"  # Local SQLite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ebfe9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InMemorySessionService stores conversations in RAM (temporary)\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Persistent memory using a SQLite database\n",
    "# SQLite database will be created automatically\n",
    "session_service = DatabaseSessionService(db_url=DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner(\n",
    "    agent=root_agent, \n",
    "    app_name=APP_NAME, \n",
    "    session_service=session_service\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3c05b",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e7fdfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Should I vaccinate?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3697, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_26908\\1760036474.py\", line 1, in <module>\n",
      "  |     response = await runner.run_debug(\n",
      "  |                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\runners.py\", line 1054, in run_debug\n",
      "  |     async for event in self.run_async(\n",
      "  |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\runners.py\", line 454, in run_async\n",
      "  |     async for event in agen:\n",
      "  |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\runners.py\", line 442, in _run_with_trace\n",
      "  |     async for event in agen:\n",
      "  |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\runners.py\", line 654, in _exec_with_plugin\n",
      "  |     async for event in agen:\n",
      "  |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\runners.py\", line 431, in execute\n",
      "  |     async for event in agen:\n",
      "  |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py\", line 291, in run_async\n",
      "  |     async for event in agen:\n",
      "  |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\agents\\sequential_agent.py\", line 77, in _run_async_impl\n",
      "  |     async for event in agen:\n",
      "  |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py\", line 291, in run_async\n",
      "  |     async for event in agen:\n",
      "  |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\agents\\parallel_agent.py\", line 206, in _run_async_impl\n",
      "  |     async for event in agen:\n",
      "  |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\agents\\parallel_agent.py\", line 145, in _merge_agent_run\n",
      "  |     async with asyncio.TaskGroup() as tg:\n",
      "  |                ^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"C:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\taskgroups.py\", line 145, in __aexit__\n",
      "  |     raise me from None\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\agents\\parallel_agent.py\", line 136, in process_an_agent\n",
      "    |     async for event in events_for_one_agent:\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py\", line 291, in run_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\agents\\llm_agent.py\", line 460, in _run_async_impl\n",
      "    |     async for event in agen:\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py\", line 346, in run_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py\", line 423, in _run_one_step_async\n",
      "    |     async for llm_response in agen:\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py\", line 801, in _call_llm_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py\", line 785, in _call_llm_with_tracing\n",
      "    |     async for llm_response in agen:\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py\", line 1038, in _run_and_handle_error\n",
      "    |     raise model_error\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py\", line 1024, in _run_and_handle_error\n",
      "    |     async for response in agen:\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\adk\\models\\google_llm.py\", line 214, in generate_content_async\n",
      "    |     response = await self.api_client.aio.models.generate_content(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\genai\\models.py\", line 7033, in generate_content\n",
      "    |     response = await self._generate_content(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\genai\\models.py\", line 5815, in _generate_content\n",
      "    |     request_dict = _GenerateContentParameters_to_mldev(\n",
      "    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\genai\\models.py\", line 1302, in _GenerateContentParameters_to_mldev\n",
      "    |     _GenerateContentConfig_to_mldev(\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\genai\\models.py\", line 1022, in _GenerateContentConfig_to_mldev\n",
      "    |     t.t_schema(api_client, getv(from_object, ['response_schema'])),\n",
      "    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\google\\genai\\_transformers.py\", line 916, in t_schema\n",
      "    |     return types.Schema.model_validate(schema)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"c:\\Users\\gabri\\workspace\\aida_projects\\vaxtalk\\.venv\\Lib\\site-packages\\pydantic\\main.py\", line 716, in model_validate\n",
      "    |     return cls.__pydantic_validator__.validate_python(\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    | pydantic_core._pydantic_core.ValidationError: 2 validation errors for Schema\n",
      "    | properties.result.discriminator\n",
      "    |   Extra inputs are not permitted [type=extra_forbidden, input_value={'mapping': {'error': '#/...propertyName': 'status'}, input_type=dict]\n",
      "    |     For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden\n",
      "    | properties.result.oneOf\n",
      "    |   Extra inputs are not permitted [type=extra_forbidden, input_value=[{'$ref': '#/$defs/Succes...#/$defs/ErrorResponse'}], input_type=list]\n",
      "    |     For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden\n",
      "    +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "response = await runner.run_debug(\n",
    "    \"Should I vaccinate?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306b73a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaxtalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
